{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c1ffba-8391-4def-a705-a4f352d0f160",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUHUYqgY6QCz",
    "outputId": "50669d06-eb8b-4819-b099-0148c300bfb1"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ea35800-b64b-4038-9b30-f0ee8990d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9ee0d43-75b4-4bdc-b6d6-591824ca7ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b3f6b92-9e5b-456e-b02b-f719c0c9924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4883c2e5-27e1-4047-9dd7-7e52a08debde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'textID', 'text', 'selected_text', 'sentiment', 'content',\n",
       "       'reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec807e-408f-406d-87bd-56a2d8c25b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d968e710-f876-4f85-9d2c-340a9e245837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"content\"] = data[\"text\"].apply(lambda x:clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0e19eca-4975-4505-a5dc-16a5a0b9762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' id have responded if i were going'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"content\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb39e00d-7b28-4bb6-b533-a03766684a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4869c992-d1c5-4066-b025-84435ab98c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"content\"] = data[\"content\"].apply(lambda x:remove_emoji(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abeb4eab-0192-40f3-a382-e25f85efaba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (1.8.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: pillow in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: six in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /Users/gopiprasanthpotipireddy/.local/lib/python3.9/site-packages (from nltk) (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e0235e-a4bf-47ed-a474-b01832d17f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gopiprasanthpotipireddy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gopiprasanthpotipireddy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2021.10.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gopiprasanthpotipireddy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "\n",
    "!pip install vaderSentiment\n",
    "\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd5e475f-633e-4356-88b3-4d1f08c57291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(text):\n",
    "     word_tokens = word_tokenize(text)\n",
    "     return  word_tokens\n",
    "data[\"reviews\"] = data[\"content\"].apply(lambda x:  token(x))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c8a9f8-6176-427d-a256-77ae6938cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "def stem_words(words):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "def lemmatize(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0b90e62-a868-457a-aa22-3161f72061b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['journey',\n",
       " 'wow',\n",
       " 'u',\n",
       " 'just',\n",
       " 'became',\n",
       " 'cooler',\n",
       " 'hehe',\n",
       " 'is',\n",
       " 'that',\n",
       " 'possible']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reviews\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0fb0a5a-8609-44f9-bd2d-27e6c6ec6321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gopiprasanthpotipireddy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4c09351-772e-40fe-8ec7-504944f9eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"selected_text\"] = data[\"reviews\"].apply(lambda x:  remove_stopwords(x))\n",
    "data[\"selected_text\"]=data[\"selected_text\"].apply(lambda x: stem_words(x))\n",
    "data[\"selected_text\"]=data[\"selected_text\"].apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f86f9a67-b30a-4089-87d5-2b60e2612ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['journey', 'wow', 'u', 'becam', 'cool', 'heh', 'poss']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"selected_text\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd329526-17b4-4957-a018-3d26836c8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str(str1).split()) \n",
    "    b = set(str(str2).split())\n",
    "    c = a.intersection(b)\n",
    "    return list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e8ca052-fc90-400d-baa4-0758821d935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for ind,row in data.iterrows():\n",
    "    sentence1 = row.selected_text\n",
    "    sentence2 = row.reviews\n",
    "    common = jaccard(sentence1,sentence2)\n",
    "    results.append(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d1b44dd-993c-4e79-9b9b-cd9367f42803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['common_words']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0000b83-cac3-428a-9d47-f514eb0ebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2,str3): \n",
    "    c1,c2,c3=0,0,0\n",
    "    for i in str1:\n",
    "         c1+=1\n",
    "    for i in str2:\n",
    "         c2+=1\n",
    "    for i in str3: \n",
    "         c3+=1   \n",
    "    return (c3) / (c1 + c2- c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9877d0cf-a575-446a-a325-5aed7c817794",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "for ind,row in data.iterrows():\n",
    "    sentence1 = row.selected_text\n",
    "    sentence2 = row.reviews\n",
    "    sentence3= row.common_words\n",
    "    common = jaccard(sentence1,sentence2,sentence3)\n",
    "    score.append(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "955f5d84-9a5e-485e-928c-421f1eee40b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score ----> 0.21862198515427156\n"
     ]
    }
   ],
   "source": [
    "print(\"similarity score\",\"---->\",sum(score)/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12ab4f73-4345-4e01-a918-f9517392e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['common_words'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec3857c0-e82d-4773-b24d-095769275d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[boss, bul]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[interview, leav, alon]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>[son, couldnt, put, releas, already, buy]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      textID                                               text  \\\n",
       "0           0  cb774db0d1                I`d have responded, if I were going   \n",
       "1           1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2           2  088c60f138                          my boss is bullying me...   \n",
       "3           3  9642c003ef                     what interview! leave me alone   \n",
       "4           4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                               selected_text sentiment  \\\n",
       "0                          [id, respond, go]   neutral   \n",
       "1              [sooo, sad, miss, san, diego]   neutral   \n",
       "2                                [boss, bul]   neutral   \n",
       "3                    [interview, leav, alon]   neutral   \n",
       "4  [son, couldnt, put, releas, already, buy]   neutral   \n",
       "\n",
       "                                             content  \\\n",
       "0                  id have responded if i were going   \n",
       "1         sooo sad i will miss you here in san diego   \n",
       "2                             my boss is bullying me   \n",
       "3                      what interview leave me alone   \n",
       "4   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                                             reviews  \n",
       "0          [id, have, responded, if, i, were, going]  \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...  \n",
       "2                       [my, boss, is, bullying, me]  \n",
       "3                [what, interview, leave, me, alone]  \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4240af9-210e-41c9-b9db-44df04af9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment=[]\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "for i in data[\"selected_text\"]:\n",
    "   sentiment_dict = sid_obj.polarity_scores(i)\n",
    "   if sentiment_dict['compound'] >= 0.05 :\n",
    "                  sentiment.append(\"positive\")\n",
    "          \n",
    "   elif sentiment_dict['compound'] <= - 0.05 :\n",
    "                   sentiment.append(\"negative\")\n",
    "          \n",
    "   else :\n",
    "                   sentiment.append(\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b2bf031-6a28-44ec-99de-df21365b2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"predicted_sentiment\"]=sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1cf85c6-cdf0-45ca-b16a-506f95218f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>reviews</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[boss, bul]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[interview, leav, alon]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>[son, couldnt, put, releas, already, buy]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      textID                                               text  \\\n",
       "0           0  cb774db0d1                I`d have responded, if I were going   \n",
       "1           1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2           2  088c60f138                          my boss is bullying me...   \n",
       "3           3  9642c003ef                     what interview! leave me alone   \n",
       "4           4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                               selected_text sentiment  \\\n",
       "0                          [id, respond, go]   neutral   \n",
       "1              [sooo, sad, miss, san, diego]   neutral   \n",
       "2                                [boss, bul]   neutral   \n",
       "3                    [interview, leav, alon]   neutral   \n",
       "4  [son, couldnt, put, releas, already, buy]   neutral   \n",
       "\n",
       "                                             content  \\\n",
       "0                  id have responded if i were going   \n",
       "1         sooo sad i will miss you here in san diego   \n",
       "2                             my boss is bullying me   \n",
       "3                      what interview leave me alone   \n",
       "4   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                                             reviews predicted_sentiment  \n",
       "0          [id, have, responded, if, i, were, going]             neutral  \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...             neutral  \n",
       "2                       [my, boss, is, bullying, me]             neutral  \n",
       "3                [what, interview, leave, me, alone]             neutral  \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...             neutral  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b67eced2-a096-4592-8108-327ee54143a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].replace(['negative', 'neutral','positive'],\n",
    "                        [0, 1,2], inplace=True)\n",
    "\n",
    "data['predicted_sentiment'].replace(['negative', 'neutral','positive'],\n",
    "                       [0, 1,2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c1e9b4a-78c4-408c-ab41-00a45817e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gopiprasanthpotipireddy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67e7f3d4-e4cc-43d4-a9ab-be156b07839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e19f7408-28c3-4cbc-a926-a4d47afc8d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974525074605138"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(data['sentiment'], data['predicted_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4da23f16-9b38-473a-8e83-0b26a2684de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.adjusted_rand_score(data['predicted_sentiment'], data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3d6a8ba-e2b1-4da6-bb16-964651fe7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       1.00      1.00      1.00     27302\n",
      "           2       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00     27478\n",
      "   macro avg       1.00      1.00      1.00     27478\n",
      "weighted avg       1.00      1.00      1.00     27478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report( data['sentiment'],data['predicted_sentiment']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
